{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and extract file from kaggle to our system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                      | 0.00/1.28M [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train.tsv.zip to .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1.28M/1.28M [00:00<00:00, 1.37MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                       | 0.00/494k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading test.tsv.zip to .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 494k/494k [00:00<00:00, 1.27MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "for file in ['train.tsv', 'test.tsv']:\n",
    "    api.competition_download_file('sentiment-analysis-on-movie-reviews', f'{file}.zip', path='./')\n",
    "\n",
    "    with zipfile.ZipFile(f'{file}.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('./')\n",
    "\n",
    "    os.remove(f'{file}.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts(normalize=True).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " From **Kaggle's website** we got following info:\n",
    " \n",
    "The sentiment labels are:\n",
    "\n",
    "0 - negative\n",
    "\n",
    "1 - somewhat negative\n",
    "\n",
    "2 - neutral\n",
    "\n",
    "3 - somewhat positive\n",
    "\n",
    "4 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing the text to create two input tensors; our input IDs, and attention mask.\n",
    "seq_len = 512 # sequence length of our tokenized sequences for BERT\n",
    "num_samples = len(df) # our token will be of shape len(df) * 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 512)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples, seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT - preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29acca873bfd4c00a8b2cfc0a0d82db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=213450.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize \n",
    "tokens = tokenizer(df['Phrase'].tolist(), max_length=seq_len, truncation=True,\n",
    "                   padding='max_length', add_special_tokens=True,\n",
    "                   return_tensors='np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,   138,  1326, ...,     0,     0,     0],\n",
       "       [  101,   138,  1326, ...,     0,     0,     0],\n",
       "       [  101,   138,  1326, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101, 13936, 25265, ...,     0,     0,     0],\n",
       "       [  101, 13936, 25265, ...,     0,     0,     0],\n",
       "       [  101, 15107,  1103, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['input_ids'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['attention_mask'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saveing them as Numpy binary files\n",
    "with open('movie-xids.npy', 'wb') as f:\n",
    "    np.save(f, tokens['input_ids'])\n",
    "    \n",
    "with open('movie-xmask.npy', 'wb') as f:\n",
    "    np.save(f, tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have them on file, we can delete the in-memory arrays to free up memory\n",
    "import gc\n",
    "del tokens \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our sentence are now ready, let's structure labels properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first extract sentiment column\n",
    "arr = df['Sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, ..., 3, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we then initialize the zero array\n",
    "labels = np.zeros((num_samples, arr.max()+1)) # shape = len(df) * number of label classes\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the current values in our arr of [0, 1, 2, 3, 4] to place 1 values in the correct positions of our presently zeros-only array\n",
    "labels[np.arange(num_samples), arr] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('movie-labels.npy', 'wb') as f:\n",
    "    np.save(f, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
